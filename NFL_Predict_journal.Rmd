---
title: "NFL Prediction"
author: "Olivier Belhumeur"
date: "November 25, 2019"
output: pdf_document
---

###Présentation

Je vais tenter de faire des prédictions sur les parties de la NFL en utilisant des principes de Régression linéaire & Machine Learning

Concretement:

#SMART

#Spécique:
Prédiction du score des deux équipes adverses pour une partie donnée

#Mesurable:
avoir une différence de moins de 9 points par équipe et prédire la victoire  

#Atteignable:
Avec mes connaissances acquises en informatique, ainsi que les informations du cours de Data Science, je serai en mesure d'effectuer des prédictions

#Temps:
Dimanche 31 mars 2020


###Journal

## Méthologie
2019-11-25

- Mon hypothèse est que je serai en mesure de prédire le score d'une partie en utilisant des données historiques des parties 

##Variables utilisées

- Points marqués en moyenne
- Point contre en moyenne
- Verge pour en moyenne
- verge contre en moyenne
- premiers essais réussis en moyenne
- premiers essais accordés en moyenne
- revirements pour
- revirements contre
- Home ou away


##Extraction des données

- Les données sont extraites pour la saison 2018 et 2019, pour chacune des rencontres

##Technique utilisée

-Régression linéaire, Méthode de Bulhmann sur les Bêta ?






### 

#2020-03-15 
- Looking for correlation and significant data









# ##################################################################################
# 
# 
# 
# 
# 
# 
# 
# lm_Ari_2019 <- lm()
# 
# Df_score <- data.frame(rep(NA, 32), nrow = 16)
#       
# for(i in 1:10){
#   test <- data.frame(Cummean_List_Stats_Teams[[i]][[1]])[-16,]
#   attach(test)
#   f <- as.formula(
#     paste("Points", 
#           paste(Var_Exp, collapse = " + "), 
#           sep = " ~ "))
#   lm_test <- lm(f)
#   (predict.lm(lm_test, newdata = data.frame(Cummean_List_Stats_Teams[[i]][[1]])[16,-1]))
#   print(Cummean_List_Stats_Teams[[i]][[1]][16,1])
#   detach(test)
#   
# }  
#   Cummean_List_Stats_Teams$ARI[[1]][1:15,1] ~  Cummean_List_Stats_Teams$ARI[[1]][1:15,2]+
#      Cummean_List_Stats_Teams$ARI[[1]][1:15,3]+
#      Cummean_List_Stats_Teams$ARI[[1]][1:15,4]+
#      Cummean_List_Stats_Teams$ARI[[1]][1:15,5]+
#      Cummean_List_Stats_Teams$ARI[[1]][1:15,6]+
#      Cummean_List_Stats_Teams$ARI[[1]][1:15,7]+
#      Cummean_List_Stats_Teams$ARI[[1]][1:15,8]+
#      Cummean_List_Stats_Teams$ARI[[1]][1:15,9])
# 
# Cummean_List_Stats_Teams$ARI[[1]][16,2:9]
# 
# predict.lm(lm_Ari_2019, newdata =  list(Cummean_List_Stats_Teams$ARI[[1]][16,2:9]))
# # for(i in seq(nrow(City_Team_Sign))){
# # 
#  Teamz_Statz <- RM_NA_List_Stats_Teams[[1]][[2]]
#  Teamz_Statz_N <- apply(Teamz_Statz, 2, as.numeric)[,-1]
# # 
# # Nb_Games_Played <- nrow(Teamz_Statz)
# # 
# # k_fold <- numeric(Nb_Games_Played)
# # 
# # for(testing in seq(Nb_Games_Played)){
# #   
# #   set.seed(0)
# #   m <- 20
# #   p <- 0.8
# #   
# #   training <- seq(Nb_Games_Played)[-testing]
# #   
# #   
# #   Points_ref <- as.numeric(Teamz_Statz[,"Points"])[-testing]
# #   Points <- Points_ref
# #   for(i in seq(m)){
# #     vecbin <- sample(seq(length(Var_Exp)),rbinom(1, length(Var_Exp), p))
# #     temp_matrix <- data.frame(cbind(Points, Teamz_Statz_N[training, vecbin]))
# #     team_rpart_temp <- rpart(Points~., data = temp_matrix,   control = rpart.control(minbucket = 2))
# #     assign(paste("team_rpart_temp", i, sep = ""), team_rpart_temp)
# #     Points <- Points - predict(team_rpart_temp)
# #   }
# #   
# #   rez_fin <- 0
# #   new_data <- data.frame(t(as.numeric(Teamz_Statz[testing,])))
# #   names(new_data) <- c("Points", Var_Exp)
# #   rez_suivi <- numeric(m)
# #   for (i in seq(m)){
# #     rez_fin = rez_fin + predict(eval(parse(text = paste("team_rpart_temp", i, sep = ""))), newdata = new_data)
# #     rez_suivi[i] <- rez_fin
# #   }
# # 
# #   print(c(Teamz_Statz[,"Points"][testing],rez_fin))
# #   plot(rez_suivi)
# #   k_fold[testing] <- rez_fin
# # }
# # 
# # 
# # }
# # point_max <- max(as.numeric(RM_NA_List_Stats_Teams[[i]][[2]][,"Points"]),k_fold)
# # plot(as.numeric(RM_NA_List_Stats_Teams[[i]][[2]][,"Points"]),round(k_fold),xlim = c(0,point_max),ylim = c(0,point_max))
# # lines(c(0,100),c(0,100))
# # lines(c(0,100),c(0,100)-3,col = "blue");lines(c(0,100),c(0,100)+3,col = "blue")
# # lines(c(0,100),c(0,100)-8,col = "red");lines(c(0,100),c(0,100)+8,col = "red")
# # 
# # summary(Points_ref - k_fold)
# 
# 
# 
# 
# 
# 
# 
# 
#  # Loaging the library
#  library(glmnet)
#  
#  # Loading the data
#  data(swiss)
#  
#  x_vars <- model.matrix(Fertility~. , swiss)[,-1]
#  y_var <- swiss$Fertility
#  lambda_seq <- 10^seq(2, -2, by = -.1)
#  
#  # Splitting the data into test and train
#  set.seed(86)
#  train = sample(1:nrow(x_vars), nrow(x_vars)/2)
#  x_test = (-train)
#  y_test = y_var[x_test]
#  
#   cv_output <- cv.glmnet(x_vars[train,], y_var[train], 
#                         alpha = 1, lambda = lambda_seq)
#  
#  # identifying best lamda
#  best_lam <- cv_output$lambda.min
# 
# 
# 
# 
# 
#  sum(Games_2018[1:32, 1] - Games_2018[1:32, 6])
#  sd(Games_2018[1:32, 6])
# 
# 
#  
#  
# 
#  
#  
#  x <- Games_2018[1:32, 1] 
#  
#  hist( x, col = "lightblue", prob = TRUE)
#  lines(density(x))
#  
#  library(fitdistrplus)
#  library(logspline)
#  
#  descdist(x, discrete = T)
# 
#  fit.weibull <- fitdist(x, "weibull")
#  fit.norm <- fitdist(x, "norm")
#  plot(fit.weibull)
# plot(fit.norm) 
# 
# fit.weibull$aic
# fit.norm$aic
# 
# 
# n.sims <- 5e4
# 
# stats <- replicate(n.sims, {      
#   r <- rweibull(n = length(x)
#                 , shape= fit.weibull$estimate["shape"]
#                 , scale = fit.weibull$estimate["scale"]
#   )
#   estfit.weibull <- fitdist(r, "weibull") # added to account for the estimated parameters
#   as.numeric(ks.test(r
#                      , "pweibull"
#                      , shape= estfit.weibull$estimate["shape"]
#                      , scale = estfit.weibull$estimate["scale"])$statistic
#   )      
# })
# 
# plot(ecdf(stats), las = 1, main = "KS-test statistic simulation (CDF)", col = "darkorange", lwd = 1.7)
# grid()
# 
# fit <- logspline(stats)
# 
# 1 - plogspline(ks.test(x
#                        , "pweibull"
#                        , shape= fit.weibull$estimate["shape"]
#                        , scale = fit.weibull$estimate["scale"])$statistic
#                , fit
# )
# 
# 
# 
# 
# 
# 
# sum_pts <- sapply(1:32, function(i) sum(as.numeric(RM_NA_List_Stats_Teams[[i]][[2]][1:15,1])))
# hist(sum_pts)
# 
# hist( sum_pts, col = "lightblue", prob = TRUE)
# lines(density(sum_pts))
# 
# library(fitdistrplus)
# library(logspline)
# 
# descdist(sum_pts, discrete = F)
# 
# fit.weibull <- fitdist(sum_pts, "weibull")
# fit.norm <- fitdist(sum_pts, "norm")
# plot(fit.weibull)
# plot(fit.norm) 
# 
# fit.weibull$aic
# fit.norm$aic
# 
# pnorm(mean(sum_pts) ,fit.norm$estimate[1],fit.norm$estimate[2])
# 
# 
# 
# 
# mean(as.numeric(RM_NA_List_Stats_Teams[[12]][[2]][seq(15), 2]))/mean(as.numeric(RM_NA_List_Stats_Teams[[12]][[2]][seq(15), 2])) * Cummean_List_Stats_Teams[[12]][[2]][15,2]
# as.numeric(RM_NA_List_Stats_Teams[[12]][[2]][16, 2])
# 
# #yards_score_gen <- function(stats){
#   
# 
# 
# 
# 
# 
# 
# 
# 
# 
# #####################################################################################################
# 
#   
#   score_mat_yards <- matrix(numeric(32 * (4 + 7 * 1)), ncol = 4 + 7 * 1)
#   
# test_impute_yards <- 
# 
#  
#   test <- numeric(32)
#   
#   for(i in seq(32)){
#   #score_mat_yards[i,(1 + 8 *(j-1))] <- as.numeric(RM_NA_List_Stats_Teams[[i]][[2]][1, 2])
#   score_mat_yards[i, 1] <- Cummean_List_Stats_Teams[[as.numeric(Data_Week[i,6,1,2])]][[1]][16,7]
#   score_mat_yards[i, 2] <- Cummean_List_Stats_Teams[[i]][[1]][16,2]
#   }
#   fit.norm <- fitdist(score_mat_yards[,1], "norm")
#   
#   for (i in seq(32)){
#     score_mat_yards[i, 3] <- 1
#     score_mat_yards[i, 4] <- prod(score_mat_yards[i,2:3])
#   }
#   
#  # pnorm( ,fit.norm$estimate[1],fit.norm$estimate[2])
#   
#   #score_mat_yards[,1] <- Cummean_List_Stats_Teams[[i]][[1]][16,1]
# #  score_mat_yards_vs <- matrix(numeric(32 * 3), ncol = 3)
#   
#   for(j in seq(1)){
#     for (i in seq(32)){
#     score_mat_yards[i,5 + 7 *(j-1)] <- as.numeric(RM_NA_List_Stats_Teams[[i]][[2]][1, 2])
#     score_mat_yards[i,6 + 7 *(j-1)] <-score_mat_yards[i,5]/score_mat_yards[i,4]
#     score_mat_yards[i,7 + 7 *(j-1)] <-score_mat_yards[i,5] - score_mat_yards[i,4]
#     score_mat_yards[i,8 + 7 *(j-1)] <- Cummean_List_Stats_Teams[[i]][[2]][16,2]
#     score_mat_yards[i,9 + 7 *(j-1)] <- Cummean_List_Stats_Teams[[as.numeric(Data_Week[i,6,(j + sum(as.numeric(Data_Week[i,6,1:j,2]) ==0 )),2])]][[2]][16,7]
#     score_mat_yards[i,10+ 7 *(j-1)] <- 1
#     score_mat_yards[i,11+ 7 *(j-1)] <- score_mat_yards[i,9 + 7 *(j-1)] * score_mat_yards[i,10 + 7 *(j-1)]
#     }
#   } 
#   
#   
#   
#   
#   
#     test <- pnorm(score_mat_yards[,4], mean(score_mat_yards[,4]), sd(score_mat_yards[,4]))*32 + 200
#     for (i in seq(32)){
#     score_mat_yards[i,(8 + 8 *(j-1))] <- test[i]/mean(test)
#       }
#   }
#   pnorm(score_mat_yards[,4], mean(score_mat_yards[,4]), sd(score_mat_yards[,4]))*32 + 200
#   
#   
# 
# #####################################################################################################  
#   
#     
#   temp_score_yards <-  pnorm(score_mat_yards[,1], mean(score_mat_yards[,1]), sd(score_mat_yards[,1]))*32 + 200
#   score_mat_yards[,3] <-  temp_score_yards/mean(temp_score_yards)
#   
#   
#   
#   
#   
#   
#   as.numeric(Data_Week[1,6,1,2])
#   
#   
#   
#   temp_score_yards_vs <- numeric(32)
#   for (i in seq(32)){
#     score_mat_yards_vs[i,1] <- as.numeric(RM_NA_List_Stats_Teams[[i]][[2]][1, 7])
#   }
#   score_mat_yards_vs[,2] <- rank(score_mat_yards_vs[,1])
#   
#   temp_score_yards_vs <-  pnorm(score_mat_yards_vs[,1], mean(score_mat_yards_vs[,1]), sd(score_mat_yards_vs[,1])) *32 + 200
#   score_mat_yards_vs[,3] <-  temp_score_yards_vs/mean(temp_score_yards_vs)
#   
#   
#   
#   Temps_Score_Yards_Tot <- matrix(numeric(32* Week), ncol = Week)
#   for(j in seq(Week)){
#     for(i in seq(32)){
#       Temps_Score_Yards_Tot[i,j] <- score_mat_yards[i,3]/score_mat_yards_vs[as.numeric(Data_Week[i,6,j,2]),3]
#       
#     }
#   }
#   
#   Score_Yards_Tot[i,j] <- score_mat_yards[12,3]/score_mat_yards_vs[as.numeric(Data_Week[12,6,2,2]),3] 
#   
#   score_mat_yards[12,3]/score_mat_yards_vs[as.numeric(Data_Week[12,6,2,2]),3]
#   
#   as.numeric(Data_Week[12,6,1,2]) * score_mat_yards[12,3]/score_mat_yards_vs[as.numeric(Data_Week[12,6,2,2]),3]
#   
#   
#   as.numeric(Data_Week[12,9,2,2])
#   
#   dif <- numeric(32)
#   for(i in seq(32)){
#   dif[i] <- (16-Weekz)/16 * mean(score_mat_yards[-i,1]) + Weekz/16 * score_mat_yards[i,3]/score_mat_yards_vs[as.numeric(Data_Week[i,6,2,2]),3] * score_mat_yards[i,1] - as.numeric(RM_NA_List_Stats_Teams[[i]][[2]][2, 2])
#   }
#   
# mean(dif)
#   
#   for(i in seq(32)){
#     valeur_test[i] <- score_mat_yards[i,3]/score_mat_yards_vs[as.numeric(Data_Week[i,6,2,2]),3]
#     
#   }
#   
# 
# 
# 
# 
# newdata <- data.frame(v_int=as.integer(c(1,1,2,NA)),
#                       v_num=as.numeric(c(1.1,NA,2.2,NA)),
#                       v_fact=as.factor(c('one','one','one',NA)),
#                       stringsAsFactors = FALSE)
# 
# #locate the NA's
# is.na(newdata)
# #how many missings per variable?
# colSums(is.na(newdata))
# #Impute on newdata
# impute(newdata,object=values) #using randomForest values
# impute(newdata,object=values2) #using median/mode values
# #One can also impute directly in newdata without the compute step
# impute(newdata)
# #Flag parameter
# impute(newdata,flag=TRUE)
# 
# 
# 
# 
# #Compute the values on a training dataset and impute them on new data.
# #This is very convenient in predictive contexts. For example:
# #define training data
# (train <- data.frame(v_int=as.integer(c(3,3,2,5,1,2,4,6)),
#                      v_num=as.numeric(c(4.1,NA,12.2,11,3.4,1.6,3.3,5.5)),
#                      v_fact=as.factor(c('one','two',NA,'two','two','one','two','two')),
#                      stringsAsFactors = FALSE))
# #Compute values on train data
# #randomForest method
# values <- compute(train, method="randomForest")
# #median/mode method
# values2 <- compute(train)
# 
# #define new data
# (newdata <- data.frame(v_int=as.integer(c(1,1,2,NA)),
#                        v_num=as.numeric(c(1.1,NA,2.2,NA)),
#                        v_fact=as.factor(c('one','one','one',NA)),
#                        stringsAsFactors = FALSE))
# #locate the NA's
# is.na(newdata)
# #how many missings per variable?
# colSums(is.na(newdata))
# #Impute on newdata
# impute(newdata,object=values) #using randomForest values
# impute(newdata,object=values2) #using median/mode values
# #One can also impute directly in newdata without the compute step
# impute(newdata)
# #Flag parameter
# impute(newdata,flag=TRUE)
# 
#   
# 
# #Loading the mice package
# library(mice)
# 
# #Loading the following package for looking at the missing values
# library(VIM)
# library(lattice)
# data(nhanes)
# str(nhanes)
# 
# #Convert Age to factor
# nhanes$age <- as.factor(nhanes$age)
#   
# #plot the missing values
# nhanes_miss <-  aggr(nhanes, col=mdc(1:2), numbers=TRUE, sortVars=TRUE, labels=names(nhanes), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
#   
# #understand the missing value pattern
# md.pattern(nhanes)
# #Drawing margin plot
# marginplot(nhanes[, c("chl", "bmi")], col = mdc(1:2), cex.numbers = 1.2, pch = 19)
# 
# 
# #Imputing missing values using mice
# mice_imputes <-  mice(nhanes, m=5, maxit = 40)
# 
# #Imputed dataset
# Imputed_data <- complete(mice_imputes,5)
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 






# 
# 
# test_impute_yards <- matrix(rep(NA, 90), ncol = 6)
# 
# 
# test_impute_yards[,1] <-  c(as.numeric(RM_NA_List_Stats_Teams[[12]][[2]][2:15,2]), NA)
# test_impute_yards[,2] <- c(as.numeric(Cummean_List_Stats_Teams[[12]][[2]][1:15,2]))
# 
# for(j in 2:16){
#   test_impute_yards[(j-1),3] <- Cummean_List_Stats_Teams[[as.numeric(Data_Week[12,6,(j + sum(as.numeric(Data_Week[12,6,1:j,2]) ==0 )),2])]][[2]][16,7]
# }
# C_rank_yards <- apply(rank_yards, 2, GMCM:::cummean)
# 
# test_impute_yards[,4] <- C_rank_yards[,12]
# 
# team_vs <- sapply(1:15, function(j) as.numeric(Data_Week[12,6,(j + sum(as.numeric(Data_Week[12,6,1:j,2]) ==0 )),2]))
# 
# 
# 
# temp_ <- numeric(15)
# for(i in seq(15)){
#   temp_[i] <- C_rank_yards[i,team_vs[i]]
# }
# test_impute_yards[,5] <- GMCM:::cummean(temp_)
# 
# test_impute_yards[,6] <- sapply(seq(15), function(i) rank_yards[i, team_vs[i]])

#test_impute_yards[(j-1),5] rank_yards[,12]

#rank_yards[,12]


#C_rank_yards <- GMCM:::cummean(sapply())

# j <- 15
# test_impute_yards[16,2] <- as.numeric(Cummean_List_Stats_Teams[[12]][[2]][16,2])
# test_impute_yards[16,3] <- Cummean_List_Stats_Teams[[as.numeric(Data_Week[12,6,(j + sum(as.numeric(Data_Week[12,6,1:j,2]) ==0 )),2])]][[2]][16,7]

# colnames(test_impute_yards) <- c("Yards", "C_Yards", "C_Yards_VS", "C_Yard_Rank", "C_Yard_Rank_VS")
# 
# train <-   as.data.frame(test_impute_yards[1:14,])
# newdata <-  as.data.frame(test_impute_yards)
# 
# #Compute values on train data
# #randomForest method
# values <- compute(train, method="randomForest")
# #median/mode method
# #values2 <- compute(train)
# 
# #locate the NA's
# is.na(newdata)
# #how many missings per variable?
# colSums(is.na(newdata))
# #Impute on newdata
# impute(newdata,object=values) #using randomForest values
# #impute(newdata,object=values2) #using median/mode values
# #One can also impute directly in newdata without the compute step
# impute(newdata)
# #Flag parameter
# impute(newdata,flag=TRUE)
# 
# test_yards <- lm(Yards~., data=newdata)
# 
# RM_NA_List_Stats_Teams[[12]][[2]][16,2]
# 
# 
# 
# 
# 
# 
#   
#   test <- numeric(32)
# 
# for(i in seq(32)){
#   #score_mat_yards[i,(1 + 8 *(j-1))] <- as.numeric(RM_NA_List_Stats_Teams[[i]][[2]][1, 2])
#   score_mat_yards[i, 1] <- Cummean_List_Stats_Teams[[as.numeric(Data_Week[i,6,1,2])]][[1]][16,7]
#   score_mat_yards[i, 2] <- Cummean_List_Stats_Teams[[i]][[1]][16,2]
# }
# fit.norm <- fitdist(score_mat_yards[,1], "norm")
# 
# for (i in seq(32)){
#   score_mat_yards[i, 3] <- 1
#   score_mat_yards[i, 4] <- prod(score_mat_yards[i,2:3])
# }
# 
# # pnorm( ,fit.norm$estimate[1],fit.norm$estimate[2])
# 
# #score_mat_yards[,1] <- Cummean_List_Stats_Teams[[i]][[1]][16,1]
# #  score_mat_yards_vs <- matrix(numeric(32 * 3), ncol = 3)
# 
# for(j in seq(1)){
#   for (i in seq(32)){
#     score_mat_yards[i,5 + 7 *(j-1)] <- as.numeric(RM_NA_List_Stats_Teams[[i]][[2]][1, 2])
#     score_mat_yards[i,6 + 7 *(j-1)] <-score_mat_yards[i,5]/score_mat_yards[i,4]
#     score_mat_yards[i,7 + 7 *(j-1)] <-score_mat_yards[i,5] - score_mat_yards[i,4]
#     score_mat_yards[i,8 + 7 *(j-1)] <- Cummean_List_Stats_Teams[[i]][[2]][16,2]
#     score_mat_yards[i,9 + 7 *(j-1)] <- Cummean_List_Stats_Teams[[as.numeric(Data_Week[i,6,(j + sum(as.numeric(Data_Week[i,6,1:j,2]) ==0 )),2])]][[2]][16,7]
#     score_mat_yards[i,10+ 7 *(j-1)] <- 1
#     score_mat_yards[i,11+ 7 *(j-1)] <- score_mat_yards[i,9 + 7 *(j-1)] * score_mat_yards[i,10 + 7 *(j-1)]
#   }
# } 



